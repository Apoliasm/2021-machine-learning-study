영향럭이 큰 특징을 상위노드로, 작은 것은 하위 노드로 

정보가 하나씩 생길때 마다 불확실성이 줄어든다. 이 불확실성을 엔트로피라고 한다. 
불확실성이 줄어든 정도 = 정보 이득
ㄴ 정보이득 = 질문 전의 엔트로피 - 질문 후의 엔트로피

특징 분류가 이진분류일때 지니 계수(Gini coefficient)사용 가능
ㄴ항상 이진 분류로 나뉠 때 , 지니계수가 높을수록 순도가 높다.
ㄴㄴ순도 : 한 그룹에 모여있는 데이터의 속성이 많이 일치한다. -> 지니계수가 높으면 데이터의 일치하는 속성이 많다. 
지니계수 = p^2 + q^2

사이킷런 이용하면 다 구한다

